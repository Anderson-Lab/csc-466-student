{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s)\n",
    "**PUT YOUR FULL NAME(S) HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should we grade this notebook? (Answer yes or no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???YES OR NO???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** Pair programming assignment. Submit only a single notebook unless you deviate significantly after lab on Thursday. If you submit individually, make sure you indicate who you worked with originally. Make sure to include your first and last names. For those students who push to individual repos but still work in groups, please indicate which notebook should be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Perceptron\n",
    "\n",
    "## Lab Assignment\n",
    "\n",
    "This is a pair programming assignment. I strongly\n",
    "discourage individual work for this (and other team/pair programming) lab(s), even if you think you can do it\n",
    "all by yourself. Also, this is a pair programming assignment, not a ”work in teams of two” assignment. Pair\n",
    "programming requires joint work on all aspects of the project without delegating portions of the work to individual\n",
    "1\n",
    "team members. For this lab, I want all your work — discussion, software development, analysis of the results,\n",
    "report writing — to be products of joint work.\n",
    "Students enrolled in the class can pair with other students enrolled in the class. Students on the waitlist can\n",
    "pair with other students on the waitlists. In the cases of ”odd person out” situations, a team of three people can\n",
    "be formed, but that team must (a) ask and answer one additional question, and (b) work as a pair would, without\n",
    "delegation of any work off-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the end of this lab, I should be able to\n",
    "* Formulate your own questions and understand how you can go about getting answers\n",
    "* Understand how to select an algorithm for your task\n",
    "* Implement ensemble methods gradient boosting and random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data\n",
    "We will be using a well known housing dataset from Boston.\n",
    "<pre>\n",
    "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
    " prices and the demand for clean air', J. Environ. Economics & Management,\n",
    " vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
    " ...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
    " pages 244-261 of the latter.\n",
    "\n",
    " Variables in order:\n",
    " CRIM     per capita crime rate by town\n",
    " ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " INDUS    proportion of non-retail business acres per town\n",
    " CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    " NOX      nitric oxides concentration (parts per 10 million)\n",
    " RM       average number of rooms per dwelling\n",
    " AGE      proportion of owner-occupied units built prior to 1940\n",
    " DIS      weighted distances to five Boston employment centres\n",
    " RAD      index of accessibility to radial highways\n",
    " TAX      full-value property-tax rate per $10,000\n",
    " PTRATIO  pupil-teacher ratio by town\n",
    " B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    " LSTAT    % lower status of the population\n",
    " MEDV     Median value of owner-occupied homes in $1000's\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"housing/boston_fixed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Read the descriptions of the questions above, and come up with three reasonable questions with corresponding methods to test them. The only one that you cannot write, is the one we will do as a class, which I use as an example here:\n",
    "\n",
    "Example questions: \n",
    "* What are factors that are most predictive of the median value of owner-occupied homes? \n",
    "* Is there a small subset of the total number of variables that could be used in predictive model and not sacrifice model accuracy?\n",
    "* Can we say that any of these factors are causing the median home values to go up? \n",
    "\n",
    "Methodology:\n",
    "1. Empirically determine the best modeling method from our known list of ensemble learners and decision trees.\n",
    "2. Using this best model, compute a feature importance score\n",
    "3. Graph the feature importance score and see if this is a dip. Use this as a cutoff if so, if not, then select the best N features and verify model performance does not change significantly.\n",
    "4. NO!!! We cannot say anything about causation with our machine learning models. There are a lot of good discussions out there on why we can't say much about casuation. [See this one for example](https://towardsdatascience.com/causality-in-machine-learning-101-for-dummies-like-me-f7f161e7383e). BUT we can say a bit about correlation and what features are impacting our overall model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR SOLUTION HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the next few questions, we will lean heavily upon sklearn and the built-in models. We'll implement our own methods later in the lab, but this is better to provide a consistent experience.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises 2-9**\n",
    "What are the factors that are most predictive of the median value of owner-occupied homes? Use the following methodology:\n",
    "\n",
    "1. Empirically determine the best modeling method from our known list of ensemble learners and decision trees (see code for more details)\n",
    "2. Using this best model, compute a feature importance score and rank the features by this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to get you started\n",
    "I included all of the imports I used in this section right here. I encourage you to take a look at their documentation. I also encourage you to try and mess with the parameters yourself and see if you can come up with better combinations. Finally, you can completely break the overall flow of what I've laid out as long as you accomplish the main goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# this is for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "import copy\n",
    "\n",
    "# our standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# of course we need to be able to split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we need a \"loss\" function\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# This is where we can get our models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# This is what I used for comparing my models\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "X = df.drop(\"MEDV\",axis=1)\n",
    "y = df[\"MEDV\"]\n",
    "\n",
    "# Below are sample arguments, manually modify some of them and see what happens (we'll do this another time with grid search)\n",
    "# Fit regression model\n",
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gb_1 = ensemble.GradientBoostingRegressor(**params)\n",
    "params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gb_2 = ensemble.GradientBoostingRegressor(**params)\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "rf_1 = RandomForestRegressor(n_estimators=100)\n",
    "rf_2 = RandomForestRegressor(n_estimators=500)\n",
    "\n",
    "models = [('Gradient Boosting 1',gb_1),('Gradient Boosting 2',gb_2),\n",
    "          ('DTree 1',regr_1),('DTree 2',regr_2),\n",
    "          ('RF 1',rf_1),('RF 2',rf_2)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** Fill in the following code that finds the mean squared error for 30 repeated hold-out cross-validation experiments for each classifier. In other words, fill in my code and produce something similar to my output. It is very important to realize that you will get different numbers since this is stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 30\n",
    "predictions = []\n",
    "ytests = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    # YOUR SOLUTION HERE\n",
    "        \n",
    "errors = {}\n",
    "for desc,model in models_train:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.927504</td>\n",
       "      <td>8.011658</td>\n",
       "      <td>71.789816</td>\n",
       "      <td>18.215877</td>\n",
       "      <td>10.344650</td>\n",
       "      <td>10.711233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>23.400873</td>\n",
       "      <td>15.439464</td>\n",
       "      <td>52.460171</td>\n",
       "      <td>25.527669</td>\n",
       "      <td>18.310141</td>\n",
       "      <td>19.253581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.012351</td>\n",
       "      <td>5.357045</td>\n",
       "      <td>16.076548</td>\n",
       "      <td>10.442792</td>\n",
       "      <td>5.610141</td>\n",
       "      <td>5.788187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.931237</td>\n",
       "      <td>6.312448</td>\n",
       "      <td>19.298800</td>\n",
       "      <td>9.475132</td>\n",
       "      <td>5.757682</td>\n",
       "      <td>5.910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11.421814</td>\n",
       "      <td>13.272938</td>\n",
       "      <td>39.172710</td>\n",
       "      <td>19.237354</td>\n",
       "      <td>12.920681</td>\n",
       "      <td>13.796592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2       RF 1  \\\n",
       "0            22.927504             8.011658  71.789816  18.215877  10.344650   \n",
       "1            23.400873            15.439464  52.460171  25.527669  18.310141   \n",
       "2             7.012351             5.357045  16.076548  10.442792   5.610141   \n",
       "3             8.931237             6.312448  19.298800   9.475132   5.757682   \n",
       "4            11.421814            13.272938  39.172710  19.237354  12.920681   \n",
       "\n",
       "        RF 2  \n",
       "0  10.711233  \n",
       "1  19.253581  \n",
       "2   5.788187  \n",
       "3   5.910600  \n",
       "4  13.796592  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>12.709624</td>\n",
       "      <td>9.928635</td>\n",
       "      <td>29.901611</td>\n",
       "      <td>20.395131</td>\n",
       "      <td>10.501303</td>\n",
       "      <td>10.490548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.383538</td>\n",
       "      <td>4.890286</td>\n",
       "      <td>13.826547</td>\n",
       "      <td>12.864321</td>\n",
       "      <td>4.952408</td>\n",
       "      <td>4.894096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>5.270724</td>\n",
       "      <td>4.019928</td>\n",
       "      <td>10.876281</td>\n",
       "      <td>9.475132</td>\n",
       "      <td>4.449443</td>\n",
       "      <td>4.728604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.523028</td>\n",
       "      <td>6.571168</td>\n",
       "      <td>19.258773</td>\n",
       "      <td>11.754125</td>\n",
       "      <td>6.875362</td>\n",
       "      <td>6.478314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>11.645045</td>\n",
       "      <td>8.249023</td>\n",
       "      <td>27.375863</td>\n",
       "      <td>17.129051</td>\n",
       "      <td>8.971444</td>\n",
       "      <td>8.509330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.567567</td>\n",
       "      <td>11.112103</td>\n",
       "      <td>37.828565</td>\n",
       "      <td>21.713074</td>\n",
       "      <td>13.750121</td>\n",
       "      <td>13.610495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>23.627587</td>\n",
       "      <td>24.925221</td>\n",
       "      <td>71.789816</td>\n",
       "      <td>68.191758</td>\n",
       "      <td>22.438754</td>\n",
       "      <td>21.794401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2  \\\n",
       "count            30.000000            30.000000  30.000000  30.000000   \n",
       "mean             12.709624             9.928635  29.901611  20.395131   \n",
       "std               5.383538             4.890286  13.826547  12.864321   \n",
       "min               5.270724             4.019928  10.876281   9.475132   \n",
       "25%               8.523028             6.571168  19.258773  11.754125   \n",
       "50%              11.645045             8.249023  27.375863  17.129051   \n",
       "75%              15.567567            11.112103  37.828565  21.713074   \n",
       "max              23.627587            24.925221  71.789816  68.191758   \n",
       "\n",
       "            RF 1       RF 2  \n",
       "count  30.000000  30.000000  \n",
       "mean   10.501303  10.490548  \n",
       "std     4.952408   4.894096  \n",
       "min     4.449443   4.728604  \n",
       "25%     6.875362   6.478314  \n",
       "50%     8.971444   8.509330  \n",
       "75%    13.750121  13.610495  \n",
       "max    22.438754  21.794401  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** Perform a one-way ANOVA to determine if there are any significant differences between methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=25.16112510189036, pvalue=4.809975117684439e-19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** Perform a post-hoc pairwise test with bonferroni multiple test correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>6.091674e-01</td>\n",
       "      <td>5.454320e-07</td>\n",
       "      <td>0.056548</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>6.091674e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>7.434107e-09</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 1</td>\n",
       "      <td>5.454320e-07</td>\n",
       "      <td>7.434107e-09</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.116769</td>\n",
       "      <td>1.770460e-08</td>\n",
       "      <td>1.679242e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 2</td>\n",
       "      <td>5.654807e-02</td>\n",
       "      <td>1.568690e-03</td>\n",
       "      <td>1.167687e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.418668e-03</td>\n",
       "      <td>3.305759e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.770460e-08</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 2</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.679242e-08</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gradient Boosting 1  Gradient Boosting 2       DTree 1  \\\n",
       "Gradient Boosting 1        -1.000000e+00         6.091674e-01  5.454320e-07   \n",
       "Gradient Boosting 2         6.091674e-01        -1.000000e+00  7.434107e-09   \n",
       "DTree 1                     5.454320e-07         7.434107e-09 -1.000000e+00   \n",
       "DTree 2                     5.654807e-02         1.568690e-03  1.167687e-01   \n",
       "RF 1                        1.000000e+00         1.000000e+00  1.770460e-08   \n",
       "RF 2                        1.000000e+00         1.000000e+00  1.679242e-08   \n",
       "\n",
       "                      DTree 2          RF 1          RF 2  \n",
       "Gradient Boosting 1  0.056548  1.000000e+00  1.000000e+00  \n",
       "Gradient Boosting 2  0.001569  1.000000e+00  1.000000e+00  \n",
       "DTree 1              0.116769  1.770460e-08  1.679242e-08  \n",
       "DTree 2             -1.000000  3.418668e-03  3.305759e-03  \n",
       "RF 1                 0.003419 -1.000000e+00  1.000000e+00  \n",
       "RF 2                 0.003306  1.000000e+00 -1.000000e+00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** Which method(s) perform the best? Consider which methods you can actually say with certainty perform better than the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** Spoiler... There should be more a few models that we are unable to distinguish using 30 trials. Rerun your above analysis, but this time repeat it with 200 trials instead of 30. Is there now a clear winner? This can definitely take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 200\n",
    "predictions = []\n",
    "ytests = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    # YOUR SOLUTION HERE\n",
    "        \n",
    "errors = {}\n",
    "for desc,model in models_train:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.652460e-14</td>\n",
       "      <td>4.723053e-61</td>\n",
       "      <td>5.764869e-11</td>\n",
       "      <td>1.049180e-07</td>\n",
       "      <td>3.816623e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>2.652460e-14</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000927e-86</td>\n",
       "      <td>5.349461e-30</td>\n",
       "      <td>1.921975e-01</td>\n",
       "      <td>3.192445e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 1</td>\n",
       "      <td>4.723053e-61</td>\n",
       "      <td>1.000927e-86</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>5.846899e-21</td>\n",
       "      <td>4.835132e-80</td>\n",
       "      <td>1.489216e-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 2</td>\n",
       "      <td>5.764869e-11</td>\n",
       "      <td>5.349461e-30</td>\n",
       "      <td>5.846899e-21</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.475878e-24</td>\n",
       "      <td>1.293922e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 1</td>\n",
       "      <td>1.049180e-07</td>\n",
       "      <td>1.921975e-01</td>\n",
       "      <td>4.835132e-80</td>\n",
       "      <td>3.475878e-24</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 2</td>\n",
       "      <td>3.816623e-08</td>\n",
       "      <td>3.192445e-01</td>\n",
       "      <td>1.489216e-80</td>\n",
       "      <td>1.293922e-24</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gradient Boosting 1  Gradient Boosting 2       DTree 1  \\\n",
       "Gradient Boosting 1        -1.000000e+00         2.652460e-14  4.723053e-61   \n",
       "Gradient Boosting 2         2.652460e-14        -1.000000e+00  1.000927e-86   \n",
       "DTree 1                     4.723053e-61         1.000927e-86 -1.000000e+00   \n",
       "DTree 2                     5.764869e-11         5.349461e-30  5.846899e-21   \n",
       "RF 1                        1.049180e-07         1.921975e-01  4.835132e-80   \n",
       "RF 2                        3.816623e-08         3.192445e-01  1.489216e-80   \n",
       "\n",
       "                          DTree 2          RF 1          RF 2  \n",
       "Gradient Boosting 1  5.764869e-11  1.049180e-07  3.816623e-08  \n",
       "Gradient Boosting 2  5.349461e-30  1.921975e-01  3.192445e-01  \n",
       "DTree 1              5.846899e-21  4.835132e-80  1.489216e-80  \n",
       "DTree 2             -1.000000e+00  3.475878e-24  1.293922e-24  \n",
       "RF 1                 3.475878e-24 -1.000000e+00  1.000000e+00  \n",
       "RF 2                 1.293922e-24  1.000000e+00 -1.000000e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gradient Boosting 2     3.053542\n",
       "RF 1                    3.815234\n",
       "RF 2                    3.866536\n",
       "Gradient Boosting 1     4.436658\n",
       "DTree 2                 5.685562\n",
       "DTree 1                12.194447\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gradient Boosting 2     9.472287\n",
       "RF 2                   10.584574\n",
       "RF 1                   10.676382\n",
       "Gradient Boosting 1    13.809749\n",
       "DTree 2                19.917827\n",
       "DTree 1                30.829403\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** Are there still any ties? If so, what are the best models? From there select the top model in terms of average error. Would this have been your same conclusion with only 30 experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** With you model of choice, calculate the mean_squared_error and r2_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 6.18\n",
      "Test Variance score: 0.92\n"
     ]
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** Now compute feature importance using the method we've developed in previous labs. I have two loops here. One is that I rerun train_test_split 50 times as you can see from above this makes a difference. Then I also permute each feature 100 times. Test your code with much smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10\n",
    "percent_diff_score = {}\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    # YOUR SOLUTION HERE\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZN          0.002132\n",
       "CHAS        0.003294\n",
       "RAD         0.020955\n",
       "INDUS       0.058049\n",
       "B           0.066190\n",
       "PTRATIO     0.142324\n",
       "AGE         0.160168\n",
       "CRIM        0.280880\n",
       "NOX         0.397836\n",
       "TAX         0.788860\n",
       "RM          7.484857\n",
       "LSTAT      12.854393\n",
       "DIS        12.861113\n",
       "Name: mean, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5ceaf1da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: I did (new_score-orig_score)/orig_score, so the most important feature is the one with the largest average difference\n",
    "percent_diff_score_data=pd.DataFrame(percent_diff_score).describe().loc['mean'].sort_values()\n",
    "display(percent_diff_score_data)\n",
    "percent_diff_score_data.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis when this notebook was last run, I would say that the three most important features are RM, DIS, and LSTAT. Let's see what happens when we compare our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 30\n",
    "predictions = []\n",
    "ytests = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    # YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All features</th>\n",
       "      <th>Subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>9.301334</td>\n",
       "      <td>14.039670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.406120</td>\n",
       "      <td>6.283578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.272045</td>\n",
       "      <td>6.512066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.754045</td>\n",
       "      <td>10.402828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.340087</td>\n",
       "      <td>12.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>10.208686</td>\n",
       "      <td>15.809693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>21.456469</td>\n",
       "      <td>33.744924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       All features     Subset\n",
       "count     30.000000  30.000000\n",
       "mean       9.301334  14.039670\n",
       "std        4.406120   6.283578\n",
       "min        3.272045   6.512066\n",
       "25%        6.754045  10.402828\n",
       "50%        8.340087  12.076811\n",
       "75%       10.208686  15.809693\n",
       "max       21.456469  33.744924"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {}\n",
    "for desc in ['All features','Subset']:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say that is not too bad of a difference in score considering we are only using 3 of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9** Now what if I told you that Random Forest and other classifiers have built-in measures for feature importance. Run the following code and compare the feature importance scores. The calculation of these needs to be saved for another time and place, but the trees themselves contain information about feature importance based on the location in the tree a feature is most often selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5cebaa630>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(n_estimators=500)\n",
    "forest.fit(X,y)\n",
    "importances = forest.feature_importances_\n",
    "importances = pd.DataFrame({'Feature':X.columns,'Importance':importances})\n",
    "importances.sort_values(by='Importance').set_index('Feature').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation from scratch portion**: We are now going to implement two ensemble learning methods from scratch and see how our implementations compare to sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** Implement a simple random forest classifier and compare the performance to one of the random forest classifiers above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn RF</th>\n",
       "      <th>Our RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>10.058503</td>\n",
       "      <td>21.267262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.051541</td>\n",
       "      <td>12.964176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.853664</td>\n",
       "      <td>8.206646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.477469</td>\n",
       "      <td>11.750554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.719413</td>\n",
       "      <td>14.957762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>13.662058</td>\n",
       "      <td>28.573571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>16.547603</td>\n",
       "      <td>46.537591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sklearn RF     Our RF\n",
       "count   10.000000  10.000000\n",
       "mean    10.058503  21.267262\n",
       "std      4.051541  12.964176\n",
       "min      3.853664   8.206646\n",
       "25%      7.477469  11.750554\n",
       "50%      8.719413  14.957762\n",
       "75%     13.662058  28.573571\n",
       "max     16.547603  46.537591"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {}\n",
    "for desc in ['sklearn RF','Our RF']:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** Implement gradient boosting from scratch using a mean squared error loss function. Compare the performance. I \"boosted\" 100 times. I've shown my validation graph. Every run is a little different, and it would definitely make this algorithm smarter if you stopped based on the validation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5cebf4518>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({\"Validation MSE\":val_mses}).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn GB</th>\n",
       "      <th>Our Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.720421</td>\n",
       "      <td>15.859993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.509146</td>\n",
       "      <td>6.387130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.743723</td>\n",
       "      <td>8.509101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.032217</td>\n",
       "      <td>11.970963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.907536</td>\n",
       "      <td>13.276280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>10.893354</td>\n",
       "      <td>18.821601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>12.151717</td>\n",
       "      <td>29.879078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sklearn GB  Our Gradient Boosting\n",
       "count   10.000000              10.000000\n",
       "mean     8.720421              15.859993\n",
       "std      2.509146               6.387130\n",
       "min      4.743723               8.509101\n",
       "25%      7.032217              11.970963\n",
       "50%      8.907536              13.276280\n",
       "75%     10.893354              18.821601\n",
       "max     12.151717              29.879078"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {}\n",
    "for desc in ['sklearn GB','Our Gradient Boosting']:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
