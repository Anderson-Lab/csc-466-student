{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s)\n",
    "**PUT YOUR FULL NAME(S) HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should we grade this notebook? (Answer yes or no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???YES OR NO???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** Pair programming assignment. Submit only a single notebook unless you deviate significantly after lab on Thursday. If you submit individually, make sure you indicate who you worked with originally. Make sure to include your first and last names. For those students who push to individual repos but still work in groups, please indicate which notebook should be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Perceptron\n",
    "\n",
    "## Lab Assignment\n",
    "\n",
    "This is a pair programming assignment. I strongly\n",
    "discourage individual work for this (and other team/pair programming) lab(s), even if you think you can do it\n",
    "all by yourself. Also, this is a pair programming assignment, not a ”work in teams of two” assignment. Pair\n",
    "programming requires joint work on all aspects of the project without delegating portions of the work to individual\n",
    "1\n",
    "team members. For this lab, I want all your work — discussion, software development, analysis of the results,\n",
    "report writing — to be products of joint work.\n",
    "Students enrolled in the class can pair with other students enrolled in the class. Students on the waitlist can\n",
    "pair with other students on the waitlists. In the cases of ”odd person out” situations, a team of three people can\n",
    "be formed, but that team must (a) ask and answer one additional question, and (b) work as a pair would, without\n",
    "delegation of any work off-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the end of this lab, I should be able to\n",
    "* Formulate your own questions and understand how you can go about getting answers\n",
    "* Understand how to select an algorithm for your task\n",
    "* Implement ensemble methods gradient boosting and random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data\n",
    "We will be using a well known housing dataset from Boston.\n",
    "<pre>\n",
    " Variables in order:\n",
    " CRIM     per capita crime rate by town\n",
    " ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " INDUS    proportion of non-retail business acres per town\n",
    " CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    " NOX      nitric oxides concentration (parts per 10 million)\n",
    " RM       average number of rooms per dwelling\n",
    " AGE      proportion of owner-occupied units built prior to 1940\n",
    " DIS      weighted distances to five Boston employment centres\n",
    " RAD      index of accessibility to radial highways\n",
    " TAX      full-value property-tax rate per $10,000\n",
    " PTRATIO  pupil-teacher ratio by town\n",
    " B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    " LSTAT    % lower status of the population\n",
    " MEDV     Median value of owner-occupied homes in $1000's\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"housing/boston_fixed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Read the descriptions of the questions above, and come up with three reasonable questions with corresponding methods to test them. The only one that you cannot write, is the one we will do as a class, which I use as an example here:\n",
    "\n",
    "Example questions: \n",
    "* What are factors that are most predictive of the median value of owner-occupied homes? \n",
    "* Is there a small subset of the total number of variables that could be used in predictive model and not sacrifice model accuracy?\n",
    "* Can we say that any of these factors are causing the median home values to go up? \n",
    "\n",
    "Methodology:\n",
    "1. Empirically determine the best modeling method from our known list of ensemble learners and decision trees.\n",
    "2. Using this best model, compute a feature importance score\n",
    "3. Graph the feature importance score and see if this is a dip. Use this as a cutoff if so, if not, then select the best N features and verify model performance does not change significantly.\n",
    "4. NO!!! We cannot say anything about causation with our machine learning models. There are a lot of good discussions out there on why we can't say much about casuation. [See this one for example](https://towardsdatascience.com/causality-in-machine-learning-101-for-dummies-like-me-f7f161e7383e). BUT we can say a bit about correlation and what features are impacting our overall model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR SOLUTION HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the next few questions, we will lean heavily upon sklearn and the built-in models. We'll implement our own methods later in the lab, but this is better to provide a consistent experience.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises 2-9**\n",
    "What are the factors that are most predictive of the median value of owner-occupied homes? Use the following methodology:\n",
    "\n",
    "1. Empirically determine the best modeling method from our known list of ensemble learners and decision trees (see code for more details)\n",
    "2. Using this best model, compute a feature importance score and rank the features by this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to get you started\n",
    "I included all of the imports I used in this section right here. I encourage you to take a look at their documentation. I also encourage you to try and mess with the parameters yourself and see if you can come up with better combinations. Finally, you can completely break the overall flow of what I've laid out as long as you accomplish the main goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "import copy\n",
    "\n",
    "# our standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# of course we need to be able to split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we need a \"loss\" function\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# This is where we can get our models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# This is what I used for comparing my models\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "X = df.drop(\"MEDV\",axis=1)\n",
    "y = df[\"MEDV\"]\n",
    "\n",
    "# Below are sample arguments, manually modify some of them and see what happens (we'll do this another time with grid search)\n",
    "# Fit regression model\n",
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gb_1 = ensemble.GradientBoostingRegressor(**params)\n",
    "params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gb_2 = ensemble.GradientBoostingRegressor(**params)\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "rf_1 = RandomForestRegressor(n_estimators=100)\n",
    "rf_2 = RandomForestRegressor(n_estimators=500)\n",
    "\n",
    "models = [('Gradient Boosting 1',gb_1),('Gradient Boosting 2',gb_2),\n",
    "          ('DTree 1',regr_1),('DTree 2',regr_2),\n",
    "          ('RF 1',rf_1),('RF 2',rf_2)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** Fill in the following code that finds the mean squared error for 30 repeated hold-out cross-validation experiments for each classifier. In other words, fill in my code and produce something similar to my output. It is very important to realize that you will get different numbers since this is stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 30\n",
    "predictions = []\n",
    "ytests = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    # YOUR SOLUTION HERE\n",
    "        \n",
    "errors = {}\n",
    "for desc,model in models_train:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.539921</td>\n",
       "      <td>6.906843</td>\n",
       "      <td>22.108259</td>\n",
       "      <td>20.163991</td>\n",
       "      <td>12.560732</td>\n",
       "      <td>9.286971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.460781</td>\n",
       "      <td>17.382044</td>\n",
       "      <td>32.871397</td>\n",
       "      <td>23.408169</td>\n",
       "      <td>17.453864</td>\n",
       "      <td>17.025082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.346346</td>\n",
       "      <td>7.687953</td>\n",
       "      <td>15.683847</td>\n",
       "      <td>13.615807</td>\n",
       "      <td>7.130643</td>\n",
       "      <td>6.705585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.168756</td>\n",
       "      <td>4.883167</td>\n",
       "      <td>36.156508</td>\n",
       "      <td>10.932996</td>\n",
       "      <td>5.660529</td>\n",
       "      <td>5.717660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.510768</td>\n",
       "      <td>7.505495</td>\n",
       "      <td>41.957346</td>\n",
       "      <td>14.025336</td>\n",
       "      <td>9.948209</td>\n",
       "      <td>9.562223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2       RF 1  \\\n",
       "0             9.539921             6.906843  22.108259  20.163991  12.560732   \n",
       "1            17.460781            17.382044  32.871397  23.408169  17.453864   \n",
       "2            13.346346             7.687953  15.683847  13.615807   7.130643   \n",
       "3             9.168756             4.883167  36.156508  10.932996   5.660529   \n",
       "4            15.510768             7.505495  41.957346  14.025336   9.948209   \n",
       "\n",
       "        RF 2  \n",
       "0   9.286971  \n",
       "1  17.025082  \n",
       "2   6.705585  \n",
       "3   5.717660  \n",
       "4   9.562223  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>11.883399</td>\n",
       "      <td>9.683125</td>\n",
       "      <td>28.917211</td>\n",
       "      <td>20.642717</td>\n",
       "      <td>10.633576</td>\n",
       "      <td>10.517292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.924642</td>\n",
       "      <td>5.944130</td>\n",
       "      <td>10.997239</td>\n",
       "      <td>10.880040</td>\n",
       "      <td>5.534104</td>\n",
       "      <td>5.556213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.579167</td>\n",
       "      <td>3.749431</td>\n",
       "      <td>14.227647</td>\n",
       "      <td>7.681839</td>\n",
       "      <td>4.529371</td>\n",
       "      <td>4.220657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.627451</td>\n",
       "      <td>5.951857</td>\n",
       "      <td>22.167827</td>\n",
       "      <td>13.632976</td>\n",
       "      <td>6.277539</td>\n",
       "      <td>6.031955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>10.590273</td>\n",
       "      <td>8.607003</td>\n",
       "      <td>26.272067</td>\n",
       "      <td>18.203397</td>\n",
       "      <td>9.907739</td>\n",
       "      <td>9.590604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>14.994481</td>\n",
       "      <td>11.317597</td>\n",
       "      <td>33.300747</td>\n",
       "      <td>25.177372</td>\n",
       "      <td>12.655157</td>\n",
       "      <td>13.549623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>23.340855</td>\n",
       "      <td>33.778558</td>\n",
       "      <td>54.051859</td>\n",
       "      <td>53.940791</td>\n",
       "      <td>30.866791</td>\n",
       "      <td>28.893415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2  \\\n",
       "count            30.000000            30.000000  30.000000  30.000000   \n",
       "mean             11.883399             9.683125  28.917211  20.642717   \n",
       "std               4.924642             5.944130  10.997239  10.880040   \n",
       "min               4.579167             3.749431  14.227647   7.681839   \n",
       "25%               8.627451             5.951857  22.167827  13.632976   \n",
       "50%              10.590273             8.607003  26.272067  18.203397   \n",
       "75%              14.994481            11.317597  33.300747  25.177372   \n",
       "max              23.340855            33.778558  54.051859  53.940791   \n",
       "\n",
       "            RF 1       RF 2  \n",
       "count  30.000000  30.000000  \n",
       "mean   10.633576  10.517292  \n",
       "std     5.534104   5.556213  \n",
       "min     4.529371   4.220657  \n",
       "25%     6.277539   6.031955  \n",
       "50%     9.907739   9.590604  \n",
       "75%    12.655157  13.549623  \n",
       "max    30.866791  28.893415  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** Perform a one-way ANOVA to determine if there are any significant differences between methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=30.14747889664212, pvalue=5.345091071433792e-22)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** Perform a post-hoc pairwise test with bonferroni multiple test correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.480826e-09</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.772836e-10</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 1</td>\n",
       "      <td>2.480826e-09</td>\n",
       "      <td>1.772836e-10</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.072676</td>\n",
       "      <td>5.472130e-10</td>\n",
       "      <td>4.598960e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 2</td>\n",
       "      <td>2.574422e-03</td>\n",
       "      <td>1.489747e-04</td>\n",
       "      <td>7.267579e-02</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.139194e-04</td>\n",
       "      <td>4.340323e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.472130e-10</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 2</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.598960e-10</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gradient Boosting 1  Gradient Boosting 2       DTree 1  \\\n",
       "Gradient Boosting 1        -1.000000e+00         1.000000e+00  2.480826e-09   \n",
       "Gradient Boosting 2         1.000000e+00        -1.000000e+00  1.772836e-10   \n",
       "DTree 1                     2.480826e-09         1.772836e-10 -1.000000e+00   \n",
       "DTree 2                     2.574422e-03         1.489747e-04  7.267579e-02   \n",
       "RF 1                        1.000000e+00         1.000000e+00  5.472130e-10   \n",
       "RF 2                        1.000000e+00         1.000000e+00  4.598960e-10   \n",
       "\n",
       "                      DTree 2          RF 1          RF 2  \n",
       "Gradient Boosting 1  0.002574  1.000000e+00  1.000000e+00  \n",
       "Gradient Boosting 2  0.000149  1.000000e+00  1.000000e+00  \n",
       "DTree 1              0.072676  5.472130e-10  4.598960e-10  \n",
       "DTree 2             -1.000000  5.139194e-04  4.340323e-04  \n",
       "RF 1                 0.000514 -1.000000e+00  1.000000e+00  \n",
       "RF 2                 0.000434  1.000000e+00 -1.000000e+00  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** Which method(s) perform the best? Consider which methods you can actually say with certainty perform better than the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** Spoiler... There should be more a few models that we are unable to distinguish using 30 trials. Rerun your above analysis, but this time repeat it with 200 trials instead of 30. Is there now a clear winner? This can definitely take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 200\n",
    "predictions = []\n",
    "ytests = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    # YOUR SOLUTION HERE\n",
    "        \n",
    "errors = {}\n",
    "for desc,model in models_train:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.621325e-12</td>\n",
       "      <td>2.585626e-66</td>\n",
       "      <td>1.283942e-11</td>\n",
       "      <td>4.071984e-06</td>\n",
       "      <td>6.911974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>1.621325e-12</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.784387e-90</td>\n",
       "      <td>1.507581e-28</td>\n",
       "      <td>2.014063e-01</td>\n",
       "      <td>4.353873e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 1</td>\n",
       "      <td>2.585626e-66</td>\n",
       "      <td>2.784387e-90</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.579233e-21</td>\n",
       "      <td>6.475009e-83</td>\n",
       "      <td>3.935068e-84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 2</td>\n",
       "      <td>1.283942e-11</td>\n",
       "      <td>1.507581e-28</td>\n",
       "      <td>1.579233e-21</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.256417e-23</td>\n",
       "      <td>1.456094e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 1</td>\n",
       "      <td>4.071984e-06</td>\n",
       "      <td>2.014063e-01</td>\n",
       "      <td>6.475009e-83</td>\n",
       "      <td>9.256417e-23</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 2</td>\n",
       "      <td>6.911974e-07</td>\n",
       "      <td>4.353873e-01</td>\n",
       "      <td>3.935068e-84</td>\n",
       "      <td>1.456094e-23</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gradient Boosting 1  Gradient Boosting 2       DTree 1  \\\n",
       "Gradient Boosting 1        -1.000000e+00         1.621325e-12  2.585626e-66   \n",
       "Gradient Boosting 2         1.621325e-12        -1.000000e+00  2.784387e-90   \n",
       "DTree 1                     2.585626e-66         2.784387e-90 -1.000000e+00   \n",
       "DTree 2                     1.283942e-11         1.507581e-28  1.579233e-21   \n",
       "RF 1                        4.071984e-06         2.014063e-01  6.475009e-83   \n",
       "RF 2                        6.911974e-07         4.353873e-01  3.935068e-84   \n",
       "\n",
       "                          DTree 2          RF 1          RF 2  \n",
       "Gradient Boosting 1  1.283942e-11  4.071984e-06  6.911974e-07  \n",
       "Gradient Boosting 2  1.507581e-28  2.014063e-01  4.353873e-01  \n",
       "DTree 1              1.579233e-21  6.475009e-83  3.935068e-84  \n",
       "DTree 2             -1.000000e+00  9.256417e-23  1.456094e-23  \n",
       "RF 1                 9.256417e-23 -1.000000e+00  1.000000e+00  \n",
       "RF 2                 1.456094e-23  1.000000e+00 -1.000000e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RF 2                    3.679515\n",
       "RF 1                    3.834495\n",
       "Gradient Boosting 2     3.852611\n",
       "Gradient Boosting 1     4.936870\n",
       "DTree 2                 5.920786\n",
       "DTree 1                10.859334\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** Are there still any ties? If so, what are the best models? From there select the top model in terms of average error. Would this have been your same conclusion with only 30 experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** With you model of choice, calculate the mean_squared_error and r2_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 4.61\n",
      "Test Variance score: 0.92\n"
     ]
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** Now compute feature importance using the method we've developed in previous labs. I have two loops here. One is that I rerun train_test_split 50 times as you can see from above this makes a difference. Then I also permute each feature 100 times. Test your code with much smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10\n",
    "percent_diff_score = {}\n",
    "iterations = {}\n",
    "experiments = {}\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    # YOUR SOLUTION HERE\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZN          0.001522\n",
       "CHAS        0.002573\n",
       "RAD         0.018705\n",
       "INDUS       0.054856\n",
       "B           0.105710\n",
       "PTRATIO     0.133865\n",
       "AGE         0.184651\n",
       "CRIM        0.294451\n",
       "NOX         0.364589\n",
       "TAX         0.839877\n",
       "RM          5.929645\n",
       "DIS        10.735753\n",
       "LSTAT      12.388118\n",
       "Name: mean, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ffdd12860>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: I did (new_score-orig_score)/orig_score, so the most important feature is the one with the largest average difference\n",
    "percent_diff_score_data=pd.DataFrame(percent_diff_score).describe().loc['mean'].sort_values()\n",
    "display(percent_diff_score_data)\n",
    "percent_diff_score_data.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis when this notebook was last run, I would say that the three most important features are RM, DIS, and LSTAT. Let's see what happens when we compare our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 30\n",
    "predictions = []\n",
    "ytests = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    # YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All features</th>\n",
       "      <th>Subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>11.005750</td>\n",
       "      <td>16.605776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.250063</td>\n",
       "      <td>6.520309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.463181</td>\n",
       "      <td>8.218935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.557377</td>\n",
       "      <td>11.134245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.732062</td>\n",
       "      <td>14.414473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.408115</td>\n",
       "      <td>22.826222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>21.485179</td>\n",
       "      <td>29.822662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       All features     Subset\n",
       "count     30.000000  30.000000\n",
       "mean      11.005750  16.605776\n",
       "std        5.250063   6.520309\n",
       "min        4.463181   8.218935\n",
       "25%        6.557377  11.134245\n",
       "50%        8.732062  14.414473\n",
       "75%       15.408115  22.826222\n",
       "max       21.485179  29.822662"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {}\n",
    "for desc in ['All features','Subset']:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say that is not too bad of a difference in score considering we are only using 3 of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9** Now what if I told you that Random Forest and other classifiers have built-in measures for feature importance. Run the following code and compare the feature importance scores. The calculation of these needs to be saved for another time and place, but the trees themselves contain information about feature importance based on the location in the tree a feature is most often selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ffdb826d8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(n_estimators=500)\n",
    "forest.fit(X,y)\n",
    "importances = forest.feature_importances_\n",
    "importances = pd.DataFrame({'Feature':X.columns,'Importance':importances})\n",
    "importances.sort_values(by='Importance').set_index('Feature').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation from scratch portion**: We are now going to implement two ensemble learning methods from scratch and see how our implementations compare to sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** Implement a simple random forest classifier and compare the performance to one of the random forest classifiers above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn RF</th>\n",
       "      <th>Our RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>12.737828</td>\n",
       "      <td>17.057502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.329105</td>\n",
       "      <td>9.236010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>7.159545</td>\n",
       "      <td>9.181140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>10.697455</td>\n",
       "      <td>11.162742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>12.498135</td>\n",
       "      <td>14.804409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>14.601846</td>\n",
       "      <td>16.960383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.954829</td>\n",
       "      <td>40.438191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sklearn RF     Our RF\n",
       "count   10.000000  10.000000\n",
       "mean    12.737828  17.057502\n",
       "std      3.329105   9.236010\n",
       "min      7.159545   9.181140\n",
       "25%     10.697455  11.162742\n",
       "50%     12.498135  14.804409\n",
       "75%     14.601846  16.960383\n",
       "max     17.954829  40.438191"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {}\n",
    "for desc in ['sklearn RF','Our RF']:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** Implement gradient boosting from scratch using a mean squared error loss function. Compare the performance. I \"boosted\" 100 times. I've shown my validation graph. Every run is a little different, and it would definitely make this algorithm smarter if you stopped based on the validation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ffcd226a0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({\"Validation MSE\":val_mses}).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn GB</th>\n",
       "      <th>Our Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.301988</td>\n",
       "      <td>15.298447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.913444</td>\n",
       "      <td>10.377214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.871719</td>\n",
       "      <td>8.623325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.359372</td>\n",
       "      <td>10.719235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.804318</td>\n",
       "      <td>12.606270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>9.495140</td>\n",
       "      <td>13.775581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>15.031566</td>\n",
       "      <td>44.240582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sklearn GB  Our Gradient Boosting\n",
       "count   10.000000              10.000000\n",
       "mean     8.301988              15.298447\n",
       "std      2.913444              10.377214\n",
       "min      4.871719               8.623325\n",
       "25%      6.359372              10.719235\n",
       "50%      7.804318              12.606270\n",
       "75%      9.495140              13.775581\n",
       "max     15.031566              44.240582"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {}\n",
    "for desc in ['sklearn GB','Our Gradient Boosting']:\n",
    "    errors[desc] = []\n",
    "    for iteration in range(num_iterations):\n",
    "        # YOUR SOLUTION HERE\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.describe()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
