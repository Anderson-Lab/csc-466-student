{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Implementation\n",
    "This is a hybird sklearn and custom random forest implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the built-in wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title of Database: Wine recognition data\n",
      "\tUpdated Sept 21, 1998 by C.Blake : Added attribute information\n",
      "\n",
      "2. Sources:\n",
      "   (a) Forina, M. et al, PARVUS - An Extendible Package for Data\n",
      "       Exploration, Classification and Correlation. Institute of Pharmaceutical\n",
      "       and Food Analysis and Technologies, Via Brigata Salerno, \n",
      "       16147 Genoa, Italy.\n",
      "\n",
      "   (b) Stefan Aeberhard, email: stefan@coral.cs.jcu.edu.au\n",
      "   (c) July 1991\n",
      "3. Past Usage:\n",
      "\n",
      "   (1)\n",
      "   S. Aeberhard, D. Coomans and O. de Vel,\n",
      "   Comparison of Classifiers in High Dimensional Settings,\n",
      "   Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
      "   Mathematics and Statistics, James Cook University of North Queensland.\n",
      "   (Also submitted to Technometrics).\n",
      "\n",
      "   The data was used with many others for comparing various \n",
      "   classifiers. The classes are separable, though only RDA \n",
      "   has achieved 100% correct classification.\n",
      "   (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
      "   (All results using the leave-one-out technique)\n",
      "\n",
      "   In a classification context, this is a well posed problem \n",
      "   with \"well behaved\" class structures. A good data set \n",
      "   for first testing of a new classifier, but not very \n",
      "   challenging.\n",
      "\n",
      "   (2) \n",
      "   S. Aeberhard, D. Coomans and O. de Vel,\n",
      "   \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
      "   Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
      "   Mathematics and Statistics, James Cook University of North Queensland.\n",
      "   (Also submitted to Journal of Chemometrics).\n",
      "\n",
      "   Here, the data was used to illustrate the superior performance of\n",
      "   the use of a new appreciation function with RDA. \n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   -- These data are the results of a chemical analysis of\n",
      "      wines grown in the same region in Italy but derived from three\n",
      "      different cultivars.\n",
      "      The analysis determined the quantities of 13 constituents\n",
      "      found in each of the three types of wines. \n",
      "\n",
      "   -- I think that the initial data set had around 30 variables, but \n",
      "      for some reason I only have the 13 dimensional version. \n",
      "      I had a list of what the 30 or so variables were, but a.) \n",
      "      I lost it, and b.), I would not know which 13 variables\n",
      "      are included in the set.\n",
      "\n",
      "   -- The attributes are (dontated by Riccardo Leardi, \n",
      "\triclea@anchem.unige.it )\n",
      " \t1) Alcohol\n",
      " \t2) Malic acid\n",
      " \t3) Ash\n",
      "\t4) Alcalinity of ash  \n",
      " \t5) Magnesium\n",
      "\t6) Total phenols\n",
      " \t7) Flavanoids\n",
      " \t8) Nonflavanoid phenols\n",
      " \t9) Proanthocyanins\n",
      "\t10)Color intensity\n",
      " \t11)Hue\n",
      " \t12)OD280/OD315 of diluted wines\n",
      " \t13)Proline            \n",
      "\n",
      "5. Number of Instances\n",
      "\n",
      "      \tclass 1 59\n",
      "\tclass 2 71\n",
      "\tclass 3 48\n",
      "\n",
      "6. Number of Attributes \n",
      "\t\n",
      "\t13\n",
      "\n",
      "7. For Each Attribute:\n",
      "\n",
      "\tAll attributes are continuous\n",
      "\t\n",
      "\tNo statistics available, but suggest to standardise\n",
      "\tvariables for certain uses (e.g. for us with classifiers\n",
      "\twhich are NOT scale invariant)\n",
      "\n",
      "\tNOTE: 1st attribute is class identifier (1-3)\n",
      "\n",
      "8. Missing Attribute Values:\n",
      "\n",
      "\tNone\n",
      "\n",
      "9. Class Distribution: number of instances per class\n",
      "\n",
      "      \tclass 1 59\n",
      "\tclass 2 71\n",
      "\tclass 3 48\n"
     ]
    }
   ],
   "source": [
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names\n",
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
    "!cat wine.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yX = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\")\n",
    "yX.columns = [\"class\",\"alcohol\",\"malic_acid\",\"ash\",\"alcalinity_ash\",\"magnesium\",\"total_phenols\",\n",
    "              \"flavanoids\",\"nonflavanoid_phenols\",\"proanthocyanins\",\"color_intensity\",\"hue\",\"OD280_over_OD315_diluted_wines\",\"proline\"]\n",
    "X = yX.drop(\"class\",axis=1)\n",
    "y = yX['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280_over_OD315_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_ash  magnesium  total_phenols  \\\n",
       "0      13.20        1.78  2.14            11.2        100           2.65   \n",
       "1      13.16        2.36  2.67            18.6        101           2.80   \n",
       "2      14.37        1.95  2.50            16.8        113           3.85   \n",
       "3      13.24        2.59  2.87            21.0        118           2.80   \n",
       "4      14.20        1.76  2.45            15.2        112           3.27   \n",
       "..       ...         ...   ...             ...        ...            ...   \n",
       "172    13.71        5.65  2.45            20.5         95           1.68   \n",
       "173    13.40        3.91  2.48            23.0        102           1.80   \n",
       "174    13.27        4.28  2.26            20.0        120           1.59   \n",
       "175    13.17        2.59  2.37            20.0        120           1.65   \n",
       "176    14.13        4.10  2.74            24.5         96           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          2.76                  0.26             1.28             4.38  1.05   \n",
       "1          3.24                  0.30             2.81             5.68  1.03   \n",
       "2          3.49                  0.24             2.18             7.80  0.86   \n",
       "3          2.69                  0.39             1.82             4.32  1.04   \n",
       "4          3.39                  0.34             1.97             6.75  1.05   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "172        0.61                  0.52             1.06             7.70  0.64   \n",
       "173        0.75                  0.43             1.41             7.30  0.70   \n",
       "174        0.69                  0.43             1.35            10.20  0.59   \n",
       "175        0.68                  0.53             1.46             9.30  0.60   \n",
       "176        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280_over_OD315_diluted_wines  proline  \n",
       "0                              3.40     1050  \n",
       "1                              3.17     1185  \n",
       "2                              3.45     1480  \n",
       "3                              2.93      735  \n",
       "4                              2.85     1450  \n",
       "..                              ...      ...  \n",
       "172                            1.74      740  \n",
       "173                            1.56      750  \n",
       "174                            1.56      835  \n",
       "175                            1.62      840  \n",
       "176                            1.60      560  \n",
       "\n",
       "[177 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    58\n",
       "3    48\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the sklearn random forest algorithm works by using the sklearn functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = sum(y_test_pred == y_test)/len(y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 1, 2, 1, 2, 3, 2, 3, 1, 3, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2,\n",
       "       2, 3, 3, 3, 2, 2, 2, 1, 1, 2, 3, 1, 1, 2, 3, 3, 2, 3, 1, 2, 2, 2,\n",
       "       3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare that to a decision tree in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train,y_train)\n",
    "dt_acc = sum(dt.predict(X_test) == y_test)/len(y_test)\n",
    "dt_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I don't know about you, but I'm sold that we should implement random forest. Here is your prompt in class. Can you and your group implement random forest using the built in decision tree classifier of sklearn? You may not look at or use the RandomForestClassifier used above. Up to the challenge? You can only use basic numpy and pandas functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=500 src=\"http://www.globalsoftwaresupport.com/wp-content/uploads/2018/02/ggff5544hh.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge Questions:\n",
    "\n",
    "How would you modify this algorithm to return the probabilities?\n",
    "\n",
    "From those probabilities, how would you create a ROC curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543859649122807"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.0,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9111111111111111,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.0,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9111111111111111,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333,\n",
       " 0.0,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9333333333333333]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
